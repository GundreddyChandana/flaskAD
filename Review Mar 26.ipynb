{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f1211b-2da8-4d54-aff6-6f72138d027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da45ddb-a057-470c-bbd3-946a8e42b510",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Jobs_Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Reading the file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m job \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJobs_Dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m job\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Jobs_Dataset.csv'"
     ]
    }
   ],
   "source": [
    "#Reading the file\n",
    "job = pd.read_csv(\"Jobs_Dataset.csv\")\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe3b82-c8c6-4f28-bfc4-c20b62c8a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a66823-2993-463f-8d97-9db976d42b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d15cba-358b-444f-ab1e-b7c3982582b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Structure\n",
    "print(type(job))\n",
    "print(job.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca318c-ddb6-4e5a-8bfa-21ede45c3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898280d9-2f55-4c87-8f82-72e3db83409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data types\n",
    "job.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e096f-189a-427d-b3ee-9fa591b0cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fc294-08bd-4d7e-8d05-2f5053bcde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = job.columns\n",
    "colours = ['blue','pink']\n",
    "sns.heatmap(job[cols].isnull(),cmap=sns.color_palette(colours),cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513aac5-eafc-4c96-a7e2-7b9161f85d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = job[['jobTitle','description','skills','client','recruiter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb23959-dcff-4ac3-8dfa-48adfea05ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cba1df-008d-4073-8c05-5dadcd0f487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jobTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c5844-38ee-4412-90f3-aa02608eb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04dfdde-3d9c-4b73-aff5-99b02c03495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72800a2-7d20-4215-b087-2279659c84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Jobs Dataset\n",
    "jobs_df = pd.read_csv(\"Jobs_Dataset.csv\")\n",
    "\n",
    "# Check for missing values and drop them\n",
    "jobs_df = jobs_df.dropna(subset=[\"minBudget\"])\n",
    "\n",
    "# Create figure with two vertically stacked subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6), gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "# Boxplot (Top subplot)\n",
    "sns.boxplot(data=jobs_df[\"minBudget\"], ax=axes[0], color='skyblue', width=0.5, orient='h')\n",
    "axes[0].set_title(\"Boxplot of minBudget Distribution\")\n",
    "axes[0].set_xlabel(\"minBudget\")\n",
    "\n",
    "# Histogram with KDE (Bottom subplot)\n",
    "sns.histplot(jobs_df[\"minBudget\"], kde=True, ax=axes[1], color='purple', bins=30)\n",
    "axes[1].set_title(\"Histogram with KDE for minBudget Distribution\")\n",
    "axes[1].set_xlabel(\"minBudget\")\n",
    "axes[1].set_ylabel(\"status\")\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8fe8d1-e7c8-4977-856c-320e11166f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.get_dummies(job,columns=['jobTitle','skills'])\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eca16c-2f0b-4ffb-984e-4757568ccda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = pd.read_csv(\"education.csv\")\n",
    "edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6add3-80e3-4b93-9ee5-abfd05a00b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650151e-d813-4156-9790-0e7efcf8b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu[\"graduationPassoutYear\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27520d-2459-4cb4-be39-2e590b7d6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262697fc-54e0-4640-84a4-e492b42cc917",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The education dataset has a column applicantId.\n",
    "- The employment dataset lists jobs but doesnâ€™t have direct user interaction data.\n",
    "- Therefore we will build a content-based job recommendation system, where each user's education profile is matched with the most relevant job descriptions/requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8350aa-2110-4240-8b3d-aeabbd3434df",
   "metadata": {},
   "source": [
    "### Preprocess the Job profiles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d934f8e-9f73-4011-a7ce-3f7cb593c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Keep only relevant columns\n",
    "job_df = job[['jobId', 'jobTitle', 'skills', 'location', 'minExp', 'maxExp', 'minBudget', 'maxBudget', 'description', 'jobType']].copy()\n",
    "\n",
    "# Drop rows with null values in critical columns\n",
    "job_df.dropna(subset=['jobId', 'skills', 'description', 'minExp', 'maxExp'], inplace=True)\n",
    "\n",
    "# Fill budget columns if needed (optional)\n",
    "job_df['minBudget'].fillna(0, inplace=True)\n",
    "job_df['maxBudget'].fillna(0, inplace=True)\n",
    "\n",
    "# Create a column for average experience required\n",
    "job_df['avgExp'] = (job_df['minExp'] + job_df['maxExp']) / 2\n",
    "\n",
    "# Combine skills and description into a single text column for NLP\n",
    "job_df['jobText'] = job_df['skills'] + ' ' + job_df['description']\n",
    "\n",
    "# Reset index after cleaning\n",
    "job_df.reset_index(drop=True, inplace=True)\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d3005-df99-4c57-8d7e-d985c2e63134",
   "metadata": {},
   "source": [
    "### Preprocess the Education data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26aa742-a1a6-4374-a2d1-3ac283a7518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep essential columns\n",
    "edu_df = edu[['applicantId', 'graduationPercentage', 'graduationPassoutYear']].copy()\n",
    "\n",
    "# Drop rows with missing applicantId or graduation year\n",
    "edu_df.dropna(subset=['applicantId', 'graduationPassoutYear'], inplace=True)\n",
    "\n",
    "# Estimate experience as current year - graduation year\n",
    "edu_df['estExp'] = 2025 - edu_df['graduationPassoutYear']\n",
    "\n",
    "# Handle invalid values (e.g., negative experience)\n",
    "edu_df['estExp'] = edu_df['estExp'].apply(lambda x: max(0, x))\n",
    "\n",
    "# Normalize education percentage (optional but useful for scoring)\n",
    "edu_df['edu_score'] = edu_df['graduationPercentage'] / 100.0\n",
    "\n",
    "# Reset index after cleaning\n",
    "edu_df.reset_index(drop=True, inplace=True)\n",
    "edu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf62253-3de0-4aea-a3a6-3d3e44874104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edu_df[edu_df[\"graduationPercentage\"]==0]))\n",
    "print(len(edu_df[edu_df[\"graduationPassoutYear\"]==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb68fa9-dc60-497e-ad63-6f333291f47f",
   "metadata": {},
   "source": [
    "### NLP: Vectorizing Job Content with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981e3a1-c78f-4a0e-8651-f60f15f8e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "\n",
    "# Fit and transform the jobText column\n",
    "job_tfidf_matrix = tfidf.fit_transform(job_df['jobText'])\n",
    "\n",
    "# Save the vocabulary if needed later for inverse transform\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "tfidf_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc779989-8126-4fa1-9950-5651b30ee455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_jobs(applicant_id, top_n=5):\n",
    "    candidate = edu_df[edu_df['applicantId'] == applicant_id]\n",
    "    if candidate.empty:\n",
    "        return f\"No candidate found with applicantId {applicant_id}\"\n",
    "    \n",
    "    candidate = candidate.iloc[0]\n",
    "    cand_exp = candidate['estExp']\n",
    "    cand_score = candidate['edu_score']\n",
    "    \n",
    "    eligible_jobs = job_df[job_df['avgExp'] <= cand_exp].copy()\n",
    "    if eligible_jobs.empty:\n",
    "        return f\"No jobs found matching experience level of {cand_exp} years\"\n",
    "    \n",
    "    eligible_indices = eligible_jobs.index.tolist()\n",
    "    eligible_tfidf = job_tfidf_matrix[eligible_indices]\n",
    "    \n",
    "    # Candidate vector (mean of job vectors as a placeholder profile)\n",
    "    candidate_vector = eligible_tfidf.mean(axis=0)\n",
    "    candidate_vector = np.asarray(candidate_vector)\n",
    "    \n",
    "    similarities = cosine_similarity(candidate_vector, eligible_tfidf).flatten()\n",
    "    eligible_jobs['similarity'] = similarities\n",
    "    \n",
    "    top_jobs = eligible_jobs.sort_values(by='similarity', ascending=False).head(top_n)\n",
    "    \n",
    "    return top_jobs[['jobId', 'jobTitle', 'location', 'minExp', 'maxExp', 'skills', 'similarity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f63bd5-9ff0-46cd-b8ab-245ac856f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend jobs for a sample applicant\n",
    "recommend_jobs('AISA9946', top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f888096-43db-4312-a77b-012d81910e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8bffa-84e3-4292-bb2c-1ddefa92f4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
